{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import gc\n",
    "import sqlalchemy as db\n",
    "from sqlalchemy import create_engine\n",
    "import pymysql\n",
    "from datetime import date, datetime\n",
    "\n",
    "import datacompy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify Path for bill dataset\n",
    "data_path1 = 'E:\\\\EASi\\\\5-Operations\\\\50-Management\\\\500-DataCentral\\\\2-Static Dashboard\\\\WIP\\\\data\\\\input\\\\validation\\\\'\n",
    "file_name1 = os.path.join(data_path1,'tc.csv')\n",
    "# Identify path for scl dataset\n",
    "data_path2 = 'E:\\\\EASi\\\\5-Operations\\\\50-Management\\\\500-DataCentral\\\\2-Static Dashboard\\\\WIP\\\\data\\\\input\\\\validation\\\\'\n",
    "file_name2 = os.path.join(data_path2,'vital.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call dataset\n",
    "df1 = pd.read_csv(file_name1)\n",
    "df2 = pd.read_csv(file_name2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify required attributes\n",
    "tc_df = df1.loc[:,['DETAILDATE', \n",
    "                   'USERPSEMPLID',\n",
    "                   'CUST_ID',\n",
    "                   'JOB_REQ_NBR',\n",
    "                   'PROJECTID',\n",
    "                   'ACTIVITYID',\n",
    "                   'HOURS',\n",
    "                   'COMMENTS'\n",
    "                  ]]\n",
    "\n",
    "init_vital_df = df2.loc[:,['Customer Id',\n",
    "                      'Employee Name',\n",
    "                      'Employee ID',\n",
    "                      'Project Id',\n",
    "                      'WBS_Activity Id',\n",
    "                      'Activity Descr',\n",
    "                      'Resource Type',\n",
    "                      'Accounting Status',\n",
    "                      'Quantity_Unit',\n",
    "                      'Transaction Date'\n",
    "                     ]]\n",
    "\n",
    "# Rename column to standardize\n",
    "tc_df.rename({'DETAILDATE':'trans_date',\n",
    "              'USERPSEMPLID':'easi_id',\n",
    "              'CUST_ID':'client_id',\n",
    "              'JOB_REQ_NBR':'job_req',\n",
    "              'PROJECTID':'proj_id',\n",
    "              'ACTIVITYID':'activity_id',\n",
    "              'HOURS':'hours',\n",
    "              'COMMENTS':'comments'\n",
    "             },axis=1, inplace=True)\n",
    "\n",
    "init_vital_df.rename({'Customer Id':'client_id',\n",
    "                 'Employee Name':'employee_name',\n",
    "                 'Employee ID':'easi_id',\n",
    "                 'Project Id':'proj_id',\n",
    "                 'WBS_Activity Id':'wbs_id',\n",
    "                 'Activity Descr':'act_desc',\n",
    "                 'Resource Type':'res_type',\n",
    "                 'Accounting Status':'acc_status',\n",
    "                 'Quantity_Unit':'hours',\n",
    "                 'Transaction Date':'trans_date'},axis=1, inplace=True)\n",
    "\n",
    "tc_df['trans_date'] = tc_df['trans_date'].astype('datetime64[ns]')\n",
    "init_vital_df['trans_date'] = init_vital_df['trans_date'].astype('datetime64[ns]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(trans_date     datetime64[ns]\n",
       " easi_id                 int64\n",
       " client_id               int64\n",
       " job_req                 int64\n",
       " proj_id                object\n",
       " activity_id            object\n",
       " hours                 float64\n",
       " comments               object\n",
       " dtype: object, client_id                 int64\n",
       " employee_name            object\n",
       " easi_id                   int64\n",
       " proj_id                  object\n",
       " wbs_id                   object\n",
       " act_desc                 object\n",
       " res_type                 object\n",
       " acc_status               object\n",
       " hours                   float64\n",
       " trans_date       datetime64[ns]\n",
       " dtype: object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Synchro data types\n",
    "tc_df.dtypes, init_vital_df.dtypes\n",
    "\n",
    "tc_df['proj_id'] = tc_df['proj_id'].astype(str)\n",
    "tc_df['hours'] = tc_df['hours'].astype('float64')\n",
    "init_vital_df['proj_id'] = init_vital_df['proj_id'].astype(str)\n",
    "tc_df.dtypes, init_vital_df.dtypes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter vital dataset as required on particular weekending\n",
    "acc_filter = ['BIL','BLD','XRV']\n",
    "res_filter = ['LABOR','SUBCN']\n",
    "\n",
    "temp_df1 = init_vital_df.loc[init_vital_df['acc_status'].isin(acc_filter)]\n",
    "vital_df = temp_df1.loc[temp_df1['res_type'].isin(res_filter)]\n",
    "vital_df = vital_df.drop(columns=['acc_status','res_type','employee_name'])\n",
    "vital_df.head(0)\n",
    "\n",
    "tc_df = tc_df.drop(columns=['comments'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-01-16 15:14:48,891 INFO sqlalchemy.engine.base.Engine SHOW VARIABLES LIKE 'sql_mode'\n",
      "2020-01-16 15:14:48,894 INFO sqlalchemy.engine.base.Engine {}\n",
      "2020-01-16 15:14:48,905 INFO sqlalchemy.engine.base.Engine SHOW VARIABLES LIKE 'lower_case_table_names'\n",
      "2020-01-16 15:14:48,907 INFO sqlalchemy.engine.base.Engine {}\n",
      "2020-01-16 15:14:48,921 INFO sqlalchemy.engine.base.Engine SELECT DATABASE()\n",
      "2020-01-16 15:14:48,923 INFO sqlalchemy.engine.base.Engine {}\n",
      "2020-01-16 15:14:48,932 INFO sqlalchemy.engine.base.Engine show collation where `Charset` = 'utf8mb4' and `Collation` = 'utf8mb4_bin'\n",
      "2020-01-16 15:14:48,934 INFO sqlalchemy.engine.base.Engine {}\n",
      "2020-01-16 15:14:48,941 INFO sqlalchemy.engine.base.Engine SELECT CAST('test plain returns' AS CHAR(60)) AS anon_1\n",
      "2020-01-16 15:14:48,943 INFO sqlalchemy.engine.base.Engine {}\n",
      "2020-01-16 15:14:48,947 INFO sqlalchemy.engine.base.Engine SELECT CAST('test unicode returns' AS CHAR(60)) AS anon_1\n",
      "2020-01-16 15:14:48,952 INFO sqlalchemy.engine.base.Engine {}\n",
      "2020-01-16 15:14:48,956 INFO sqlalchemy.engine.base.Engine SELECT CAST('test collated returns' AS CHAR CHARACTER SET utf8mb4) COLLATE utf8mb4_bin AS anon_1\n",
      "2020-01-16 15:14:48,957 INFO sqlalchemy.engine.base.Engine {}\n",
      "2020-01-16 15:14:48,962 INFO sqlalchemy.engine.base.Engine SELECT EASiID as easi_id, FullName as resource, Department as department FROM personnelt WHERE Active='Yes' AND ClientCode NOT IN(SELECT clientCode from personnelt WHERE clientcode IN('','Internal'))\n",
      "2020-01-16 15:14:48,964 INFO sqlalchemy.engine.base.Engine {}\n"
     ]
    }
   ],
   "source": [
    "# Add Resource connectivity\n",
    "engine = db.create_engine('mysql+pymysql://admin:password@10.140.9.93:3306/datacentralserver', echo=True)\n",
    "resource_df = pd.read_sql_query(\"SELECT EASiID as easi_id, FullName as resource, Department as department FROM personnelt WHERE Active='Yes' AND ClientCode NOT IN(SELECT clientCode from personnelt WHERE clientcode IN('','Internal'))\",engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((491, 7), (518, 7), 2960.0, 3150.0)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tc_df.shape, vital_df.shape, tc_df['hours'].sum(), vital_df['hours'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trans_date</th>\n",
       "      <th>easi_id</th>\n",
       "      <th>client_id</th>\n",
       "      <th>job_req</th>\n",
       "      <th>proj_id</th>\n",
       "      <th>activity_id</th>\n",
       "      <th>hours</th>\n",
       "      <th>wbs_id</th>\n",
       "      <th>act_desc</th>\n",
       "      <th>_merge</th>\n",
       "      <th>resource</th>\n",
       "      <th>department</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-11-25</td>\n",
       "      <td>4563307</td>\n",
       "      <td>266644</td>\n",
       "      <td>5371058</td>\n",
       "      <td>EM1-0063-SIE</td>\n",
       "      <td>P03-370364-ASP</td>\n",
       "      <td>2.0</td>\n",
       "      <td>P03-370364-ASP</td>\n",
       "      <td>RD341PMP-02-04-OUT</td>\n",
       "      <td>both</td>\n",
       "      <td>Haq,Sohail</td>\n",
       "      <td>MEC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-11-25</td>\n",
       "      <td>4563307</td>\n",
       "      <td>266644</td>\n",
       "      <td>5371058</td>\n",
       "      <td>EM1-0063-SIE</td>\n",
       "      <td>P01-370364-AM</td>\n",
       "      <td>6.0</td>\n",
       "      <td>P01-370364-AM</td>\n",
       "      <td>RD341PMP-02-02-OUT</td>\n",
       "      <td>both</td>\n",
       "      <td>Haq,Sohail</td>\n",
       "      <td>MEC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-11-25</td>\n",
       "      <td>5518599</td>\n",
       "      <td>266644</td>\n",
       "      <td>5301971</td>\n",
       "      <td>E1B100500639</td>\n",
       "      <td>M01-500639</td>\n",
       "      <td>2.0</td>\n",
       "      <td>M01-500639</td>\n",
       "      <td>RD341MFG-01-08</td>\n",
       "      <td>both</td>\n",
       "      <td>Mohan,Inder</td>\n",
       "      <td>MEC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-11-26</td>\n",
       "      <td>5518599</td>\n",
       "      <td>266644</td>\n",
       "      <td>5301971</td>\n",
       "      <td>E1B100500639</td>\n",
       "      <td>M01-500639</td>\n",
       "      <td>8.0</td>\n",
       "      <td>M01-500639</td>\n",
       "      <td>RD341MFG-01-08</td>\n",
       "      <td>both</td>\n",
       "      <td>Mohan,Inder</td>\n",
       "      <td>MEC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-11-27</td>\n",
       "      <td>5518599</td>\n",
       "      <td>266644</td>\n",
       "      <td>5301971</td>\n",
       "      <td>E1B100500639</td>\n",
       "      <td>M01-500639</td>\n",
       "      <td>9.0</td>\n",
       "      <td>M01-500639</td>\n",
       "      <td>RD341MFG-01-08</td>\n",
       "      <td>both</td>\n",
       "      <td>Mohan,Inder</td>\n",
       "      <td>MEC</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  trans_date  easi_id  client_id  job_req       proj_id     activity_id  \\\n",
       "0 2019-11-25  4563307     266644  5371058  EM1-0063-SIE  P03-370364-ASP   \n",
       "1 2019-11-25  4563307     266644  5371058  EM1-0063-SIE   P01-370364-AM   \n",
       "2 2019-11-25  5518599     266644  5301971  E1B100500639      M01-500639   \n",
       "3 2019-11-26  5518599     266644  5301971  E1B100500639      M01-500639   \n",
       "4 2019-11-27  5518599     266644  5301971  E1B100500639      M01-500639   \n",
       "\n",
       "   hours          wbs_id            act_desc _merge     resource department  \n",
       "0    2.0  P03-370364-ASP  RD341PMP-02-04-OUT   both   Haq,Sohail        MEC  \n",
       "1    6.0   P01-370364-AM  RD341PMP-02-02-OUT   both   Haq,Sohail        MEC  \n",
       "2    2.0      M01-500639      RD341MFG-01-08   both  Mohan,Inder        MEC  \n",
       "3    8.0      M01-500639      RD341MFG-01-08   both  Mohan,Inder        MEC  \n",
       "4    9.0      M01-500639      RD341MFG-01-08   both  Mohan,Inder        MEC  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_df = pd.merge(tc_df, vital_df, how='inner', indicator=True, on=['easi_id','proj_id','trans_date','client_id','hours'])\n",
    "temp_df2 = pd.merge(temp_df, resource_df,how='left', on='easi_id')\n",
    "temp_df3 = temp_df2.groupby('proj_id')['hours'].sum()\n",
    "temp_df2.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
