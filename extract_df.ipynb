{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'mysql'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-a1f4ddacb802>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msqlalchemy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mdb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mmysql\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconnector\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mmysql\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconnector\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0merrorcode\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msqlalchemy\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcreate_engine\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'mysql'"
     ]
    }
   ],
   "source": [
    "# Import Library\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import sqlalchemy as db\n",
    "import mysql.connector\n",
    "from mysql.connector import errorcode\n",
    "from sqlalchemy import create_engine\n",
    "import pymysql\n",
    "import xlrd\n",
    "import decimal\n",
    "from datetime import date, datetime\n",
    "\n",
    "D = decimal.Decimal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path1 = 'C:\\\\Users\\\\fwidjojoputra\\\\Desktop\\\\data\\\\'\n",
    "data_path2 = 'E:\\\\EASi\\\\5-Operations\\\\50-Management\\\\500-DataCentral\\\\3-Super User\\\\Development\\\\data_repository\\\\msp_data\\\\'\n",
    "\n",
    "file_name1 = os.path.join(data_path1,'resources.csv') \n",
    "file_name2 = os.path.join(data_path1,'projects.csv') \n",
    "file_name3 = os.path.join(data_path1,'tasks.csv') \n",
    "file_name4 = os.path.join(data_path1,'assignments.csv') \n",
    "file_name5 = os.path.join(data_path1,'tasktime_phased.csv')\n",
    "file_name6 = os.path.join(data_path2,'psoft_data.csv')\n",
    "file_name7 = os.path.join(data_path2,'psoft_prj_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(file_name1) # res\n",
    "df2 = pd.read_csv(file_name2) # prj\n",
    "df3 = pd.read_csv(file_name3) # task\n",
    "df4 = pd.read_csv(file_name4) # ass\n",
    "df5 = pd.read_csv(file_name5) # task_tp\n",
    "df6 = pd.read_csv(file_name6) # psoft_data\n",
    "df7 = pd.read_csv(file_name7) # psoft__prj_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------- Data prep RESOURCES --------------------#\n",
    "res_df = df1.loc[:,['DataCentralID',\n",
    "                    'ResourceId']]\n",
    "\n",
    "prj_df = df2.loc[:,['ProjectId',\n",
    "                    'SOWNb',\n",
    "                    'ProjectActualFinishDate',\n",
    "                    'year']]\n",
    "\n",
    "tsk_df = df3.loc[:,['TaskId',\n",
    "                    'ParentTaskId',\n",
    "                    'ProjectId',\n",
    "                    'TaskName']]\n",
    "\n",
    "ass_df = df4.loc[:,['ProjectId',\n",
    "                    'TaskId',\n",
    "                    'AssignmentId',\n",
    "                    'ResourceId']]\n",
    "\n",
    "tsktp_df = df5.loc[:,['TaskId',\n",
    "                      'ProjectId',\n",
    "                      'TaskWork',\n",
    "                      'TaskCost',\n",
    "                      'TaskName']] \n",
    "\n",
    "psoft_df = df6.loc[:,['Customer',\n",
    "                      'Category',\n",
    "                      'Order No',\n",
    "                      'Job Req #',\n",
    "                      'ID',\n",
    "                      'Name',\n",
    "                      'Earn Code',\n",
    "                      'Blended Rate',\n",
    "                      'Job Code']]\n",
    "\n",
    "psoft_prj_df = df7.loc[:,['Project',\n",
    "                          'Psoft Project ID',\n",
    "                          'EASi ID',\n",
    "                          'Job Req',\n",
    "                          'Bill Rate']]\n",
    "\n",
    "res_df.rename({'DataCentralID':'easi_id',\n",
    "               'ResourceId':'res_id'},axis=1, inplace=True)\n",
    "\n",
    "prj_df.rename({'SOWNb':'sow_no',\n",
    "               'ProjectId':'prj_id',\n",
    "               'ProjectActualFinishDate':'end_date'},axis=1, inplace=True)\n",
    "\n",
    "tsk_df.rename({'TaskId':'task_id',\n",
    "               'ParentTaskId':'parent_id',\n",
    "               'ProjectId':'prj_id',\n",
    "               'TaskName':'task_name'},axis=1, inplace=True)\n",
    "\n",
    "ass_df.rename({'ProjectId':'prj_id',\n",
    "                'TaskId':'task_id',\n",
    "                'AssignmentId':'ass_id',\n",
    "                'ResourceId':'res_id'},axis=1, inplace=True)\n",
    "\n",
    "tsktp_df.rename({'TaskId':'task_id',\n",
    "                 'ProjectId':'prj_id',\n",
    "                 'TaskWork':'task_work',\n",
    "                 'TaskCost':'task_cost',\n",
    "                 'TaskName':'task_name'},axis=1, inplace=True)\n",
    "\n",
    "psoft_df.rename({'Customer':'client',\n",
    "                 'Category':'cat',\n",
    "                 'Order No':'ord_no',\n",
    "                 'Job Req #':'job_req',\n",
    "                 'ID':'easi_id',\n",
    "                 'Name':'res_name',\n",
    "                 'Earn Code':'earn_code',\n",
    "                 'Blended Rate':'br',\n",
    "                 'Job Code':'job_code'},axis=1, inplace=True)\n",
    "\n",
    "psoft_prj_df.rename({'Project':'sow_no',\n",
    "                     'Psoft Project ID':'psoft_prj_id',\n",
    "                     'EASi ID':'easi_id',\n",
    "                     'Job Req':'job_req',\n",
    "                     'Bill Rate':'br'},axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prj_tsk_df = tsk_df.merge(prj_df, on='prj_id', how='left')\n",
    "prj_task_ass_df = prj_tsk_df.merge(ass_df, on='task_id', how='inner')\n",
    "prj_task_ass_res_df = prj_task_ass_df.merge(res_df, on='res_id', how='left')\n",
    "\n",
    "# group dataset by task_id\n",
    "task_timephased_df = tsktp_df.groupby('task_id')['task_work','task_cost'].sum()\n",
    "tsktp_df1 = task_timephased_df.reset_index()\n",
    "tsktp_df1['br'] = tsktp_df1['task_cost']/tsktp_df1['task_work']\n",
    "\n",
    "all_df = prj_task_ass_res_df.merge(tsktp_df1, on='task_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert easi id to int\n",
    "all_df = all_df.fillna(value='0')\n",
    "test_df = all_df[all_df.easi_id != 'xxx']\n",
    "test_df['easi_id'] = test_df['easi_id'].astype('int64')\n",
    "test_df['br'] = test_df['br'].astype('float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove id 0 and 1\n",
    "test_df2 = test_df[test_df.easi_id != 0]\n",
    "test_df3 = test_df2[test_df2.easi_id != 1]\n",
    "test_df = test_df3.round(2)\n",
    "# Collect required data for merging\n",
    "init_df = test_df.loc[:,['sow_no',\n",
    "                        'task_name',\n",
    "                        'easi_id',\n",
    "                        'br']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_df['easi_id'].nunique(), init_df.shape\n",
    "init_df['br'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle psoft data\n",
    "# psoft_df['easi_id'].nunique(), psoft_df.shape\n",
    "psoft_df['br'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Combined set\n",
    "final_df = init_df.merge(psoft_df, left_on=['easi_id','br'], right_on=['easi_id','br'], how='inner')\n",
    "final_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.shape, psoft_prj_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_df = final_df.merge(psoft_prj_df, left_on=['sow_no','easi_id','br','job_req'], right_on=['sow_no','easi_id','br','job_req'], how='inner')\n",
    "extract_df.head(50) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
