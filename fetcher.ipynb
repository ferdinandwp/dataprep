{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import library\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import os \n",
    "import glob \n",
    "import sys \n",
    "from sqlalchemy import create_engine \n",
    "import sqlalchemy as db \n",
    "\n",
    "from fetcher.async_fetcher import FetchMSPDataAsync "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------- Getting available fields in MSP Project Online -------\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'l' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-909755544417>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m             \u001b[1;33m[\u001b[0m\u001b[0mMSP_ROOT_URL\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mMSP_USERNAME\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mMSP_PASS\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m             [\n\u001b[1;32m---> 10\u001b[1;33m                 \u001b[1;34m\"Projects\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;31m#                 \"Tasks\",\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;31m#                 \"Assignments\",\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\dataprep\\fetcher\\async_fetcher.py\u001b[0m in \u001b[0;36mFetchMSPDataAsync\u001b[1;34m(auth_creds, endpoint_list)\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mstart_time2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"------- Getting available fields in MSP Project Online -------\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m     \u001b[0mavailable_fields\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFetchMSPAvailableFields\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mauth_creds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mendpoint_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\dataprep\\fetcher\\fetcher.py\u001b[0m in \u001b[0;36mFetchMSPAvailableFields\u001b[1;34m(auth_creds)\u001b[0m\n\u001b[0;32m    109\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0melem\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"None\"\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0melem\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"Default\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m                     \u001b[0ml\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0melem\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 111\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    112\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnboundLocalError\u001b[0m: local variable 'l' referenced before assignment"
     ]
    }
   ],
   "source": [
    "MSP_ROOT_URL = \"https://allegiscloud.sharepoint.com\"\n",
    "MSP_USERNAME = \"fwidjojoputra@easi.com\"\n",
    "MSP_PASS = \"Dart23499\"\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    table_df_dict = FetchMSPDataAsync(\n",
    "            [MSP_ROOT_URL, MSP_USERNAME, MSP_PASS],\n",
    "            [\n",
    "                \"Projects\"\n",
    "#                 \"Tasks\",\n",
    "#                 \"Assignments\",\n",
    "#                 \"Resources\"\n",
    "#                 \"ResourceTimephasedDataSet\",\n",
    "#                 \"ResourceDemandTimephasedDataSet\",\n",
    "#                 \"AssignmentTimephasedDataSet\",\n",
    "#                 \"AssignmentBaselineTimephasedDataSet\",\n",
    "#                 \"ProjectBaselines\"            \n",
    "            ],\n",
    "        ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch dataframe\n",
    "prj_df = table_df_dict['Projects']\n",
    "tsk_df = table_df_dict['Tasks']\n",
    "ass_df = table_df_dict['Assignments']\n",
    "res_df = table_df_dict['Resources']\n",
    "rt_df = table_df_dict['ResourceTimephasedDataSet']\n",
    "rdt_df = table_df_dict['ResourceDemandTimephasedDataSet'] # May not need this\n",
    "ast_df = table_df_dict['AssignmentTimephasedDataSet']\n",
    "asbt_df = table_df_dict['AssignmentBaselineTimephasedDataSet']\n",
    "prjb_df = table_df_dict['ProjectBaselines']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prj_df.shape, res_df.shape, ass_df.shape, tsk_df.shape, rdt_df.shape, rt_df.shape, ast_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter active vs unactive project\n",
    "prj_df = prj_df[prj_df.ProjectActualFinishDate.isnull()]\n",
    "res_df = res_df[res_df['DataCentralID'].apply(lambda x: len(str(x)) == 8)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAIN DATAFRAME\n",
    "temp1_df = prj_df.merge(tsk_df, left_on='ProjectId', right_on='ProjectId', how='right') # This is for project and task dataset\n",
    "temp2_df = temp1_df.merge(ass_df, left_on='TaskId', right_on='TaskId', how='inner')     # join to assignment df\n",
    "temp3_df = temp2_df.loc[temp2_df['ResourceId'].isin(res_df['ResourceId'])]\n",
    "\n",
    "nature_filter = ['Actual Work','Potential Work','At risk Work']\n",
    "temp4_df = temp3_df.loc[temp3_df['ProjectNature'].isin(nature_filter)]\n",
    "temp5_df = temp4_df.loc[:,['ResourceId',\n",
    "                           'ProjectNature']]\n",
    "\n",
    "temp5_df.rename({'ProjectNature':'work_nature'}, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CAPACITY DATASET\n",
    "rt_temp_df = rt_df.loc[rt_df['ResourceId'].isin(res_df['ResourceId'])]\n",
    "res_capacity_df = rt_temp_df.merge(res_df, left_on=['ResourceId','ResourceName','ResourceModifiedDate'], right_on=['ResourceId','ResourceName','ResourceModifiedDate'], how='inner')\n",
    "\n",
    "# DEMAND DATASET\n",
    "rdt_temp_df = rdt_df.loc[rdt_df['ResourceId'].isin(res_df['ResourceId'])]\n",
    "res_demand_df = rdt_temp_df.merge(res_df, left_on=['ResourceId','ResourceName'], right_on=['ResourceId','ResourceName'], how='inner')\n",
    "\n",
    "# MERGE LOAD & CAPACITY\n",
    "combined_df = res_capacity_df.merge(res_demand_df, on=['ResourceId','TimeByDay'], how='inner')\n",
    "\n",
    "# DATA LOC for processing\n",
    "dem_cap_df = combined_df.loc[:,['ResourceId',\n",
    "                                'DataCentralID_x',\n",
    "                                'TimeByDay',\n",
    "                                'Capacity',\n",
    "                                'ResourceDemand']]\n",
    "dem_cap_df.rename({'DataCentralID_x':'easi_id',\n",
    "                   'TimeByDay':'time',\n",
    "                   'Capacity':'capacity',\n",
    "                   'ResourceDemand':'demand'},axis=1,inplace=True)\n",
    "dem_cap_df.dropna()\n",
    "dem_cap_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMBINED MAIN DATAFRAME & LOAD CAP DATAFRAME\n",
    "x = dem_cap_df.merge(temp5_df, on='ResourceId', how='inner')\n",
    "\n",
    "# Change datatypes for optmization\n",
    "x['easi_id'] = x['easi_id'].astype('int64')\n",
    "x['demand'] = x['demand'].astype('float16')\n",
    "x['capacity'] = x['capacity'].astype('float16')\n",
    "x['time'] = x['time'].astype('datetime64[ns]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CALL DATASET FROM DB\n",
    "engine = db.create_engine('mysql+pymysql://mikeez:maikil@10.140.9.15:3306/dc_dev', echo=False)\n",
    "res_db_df = pd.read_sql_query(\"SELECT easi_id, first_name, last_name, team, base FROM resources\", engine)\n",
    "team_db_df = pd.read_sql_query(\"SELECT * FROM teams\", engine)\n",
    "dep_db_df =  pd.read_sql_query(\"SELECT * FROM departments\", engine)\n",
    "\n",
    "# Data prep\n",
    "db1_df = res_db_df.merge(team_db_df, left_on='team', right_on='id', how='left')\n",
    "db2_df = db1_df.merge(dep_db_df, left_on='department',right_on='id', how='left')\n",
    "db2_df['full_name'] = db2_df['last_name'] + \",\" + db2_df['first_name']\n",
    "db3_df = db2_df.loc[:,['easi_id',\n",
    "                      'full_name',\n",
    "                      'name_x',\n",
    "                      'name_y'\n",
    "                      ]]\n",
    "db3_df.rename({'name_x':'team',\n",
    "               'name_y':'department'}, axis=1, inplace=True)\n",
    "\n",
    "res_db_fil = ['MEC','SES']\n",
    "db4_df = db3_df.loc[db3_df['department'].isin(res_db_fil)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# JOIN WITH DB DATAFRAME\n",
    "x1 = x.merge(db4_df, left_on='easi_id', right_on='easi_id', how='inner')\n",
    "\n",
    "x2 = x1.loc[:,['work_nature',\n",
    "               'demand',\n",
    "               'capacity',\n",
    "               'time',\n",
    "               'full_name',\n",
    "               'team',\n",
    "               'department']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FILTER OUT EXPIRED DATASET\n",
    "end_df = x2.loc[x2['time'] > '2019-12-31']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into 3 dataframes depending on work nature\n",
    "end_df['time'] = pd.to_datetime(end_df['time']).apply(lambda x: '{year}-{month}'.format(year=x.year, month=x.month))\n",
    "\n",
    "act_filter = ['Actual Work']\n",
    "pot_filter = ['Potential Work']\n",
    "ris_filter = ['At risk Work']\n",
    "\n",
    "act_df = end_df.loc[end_df['work_nature'].isin(act_filter)]\n",
    "pot_df = end_df.loc[end_df['work_nature'].isin(pot_filter)]\n",
    "ris_df = end_df.loc[end_df['work_nature'].isin(ris_filter)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by the time and name\n",
    "act_agg_df = act_df.groupby(['full_name','time'])['demand','capacity'].sum().reset_index()\n",
    "pot_agg_df = pot_df.groupby(['full_name','time'])['demand','capacity'].sum().reset_index()\n",
    "ris_agg_df = ris_df.groupby(['full_name','time'])['demand','capacity'].sum().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "act_agg_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "end_df['time'] = pd.to_datetime(end_df['time']).apply(lambda x: '{year}-{month}'.format(year=x.year, month=x.month))\n",
    "test = end_df.groupby(['full_name','time'])['demand','capacity'].sum().reset_index()\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INJECT TO DB\n",
    "# end_df.to_sql('timephases',con=engine, if_exists='append', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---------------------- TO BE TESTED----------------------#\n",
    "#------------- TEST METHOD SPLIT per dataset -------------#\n",
    "#----------------------TO BE TESTED----------------------#\n",
    "res_cap_df = res_capacity_df.loc[:,['ResourceId',\n",
    "                                     'Capacity',\n",
    "                                     'TimeByDay',\n",
    "                                     'DataCentralID'\n",
    "                                    ]]\n",
    "\n",
    "res_cap_df.rename({'Capacity':'capacity',\n",
    "                    'TimeByDay':'time',\n",
    "                    'DataCentralID':'easi_id'}, axis=1, inplace=True)\n",
    "\n",
    "\n",
    "res_cap_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp5_df.loc[temp5_df['ResourceId']== 'ee4cf8ec-b0de-e811-9640-d4258bdae0ca']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge with main df\n",
    "z = res_cap_df.merge(temp5_df, on='ResourceId', how='inner')\n",
    "\n",
    "# convert dataset\n",
    "z['easi_id'] = z['easi_id'].astype('int64')\n",
    "z['capacity'] = z['capacity'].astype('float16')\n",
    "z['time'] = z['time'].astype('datetime64[ns]')\n",
    "z['capacity'] = z['capacity'].apply(lambda x: round(x,1))\n",
    "\n",
    "# JOIN WITH DB DATAFRAME\n",
    "z1 = z.merge(db4_df, left_on='easi_id', right_on='easi_id', how='inner')\n",
    "\n",
    "z2 = z1.loc[:,['work_nature',\n",
    "               'capacity',\n",
    "               'time',\n",
    "               'full_name',\n",
    "               'team',\n",
    "               'department']]\n",
    "\n",
    "\n",
    "z2['time'] = pd.to_datetime(z['time']).apply(lambda x: '{year}-{month}'.format(year=x.year, month=x.month))\n",
    "\n",
    "z2_act_filter = ['Actual Work']\n",
    "z2_pot_filter = ['Potential Work']\n",
    "z2_ris_filter = ['At risk Work']\n",
    "\n",
    "z2_act_df = z2.loc[z2['work_nature'].isin(z2_act_filter)]\n",
    "z2_pot_df = z2.loc[z2['work_nature'].isin(z2_pot_filter)]\n",
    "z2_ris_df = z2.loc[z2['work_nature'].isin(z2_ris_filter)]\n",
    "\n",
    "z2_act_df = z2_act_df.loc[z2_act_df['time'] > '2020-00']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z3 = z2_act_df.loc[z2_act_df['time'] > '2020-00']\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
